{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment: Ionosphere Data Problem\n",
    "\n",
    "### Dataset Description: \n",
    "\n",
    "This radar data was collected by a system in Goose Bay, Labrador. This system consists of a phased array of 16 high-frequency antennas with a total transmitted power on the order of 6.4 kilowatts. See the paper for more details. The targets were free electrons in the ionosphere. \"Good\" radar returns are those showing evidence of some type of structure in the ionosphere. \"Bad\" returns are those that do not; their signals pass through the ionosphere.\n",
    "\n",
    "Received signals were processed using an autocorrelation function whose arguments are the time of a pulse and the pulse number. There were 17 pulse numbers for the Goose Bay system. Instances in this databse are described by 2 attributes per pulse number, corresponding to the complex values returned by the function resulting from the complex electromagnetic signal.\n",
    "\n",
    "### Attribute Information:\n",
    "\n",
    "- All 34 are continuous\n",
    "- The 35th attribute is either \"good\" or \"bad\" according to the definition summarized above. This is a binary classification task.\n",
    "\n",
    " <br><br>\n",
    "\n",
    "<table border=\"1\"  cellpadding=\"6\">\n",
    "\t<tbody>\n",
    "        <tr>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Data Set Characteristics:&nbsp;&nbsp;</b></p></td>\n",
    "\t\t<td><p class=\"normal\">Multivariate</p></td>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Number of Instances:</b></p></td>\n",
    "\t\t<td><p class=\"normal\">351</p></td>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Area:</b></p></td>\n",
    "\t\t<td><p class=\"normal\">Physical</p></td>\n",
    "        </tr>\n",
    "     </tbody>\n",
    "    </table>\n",
    "<table border=\"1\" cellpadding=\"6\">\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Attribute Characteristics:</b></p></td>\n",
    "            <td><p class=\"normal\">Integer,Real</p></td>\n",
    "            <td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Number of Attributes:</b></p></td>\n",
    "            <td><p class=\"normal\">34</p></td>\n",
    "            <td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Date Donated</b></p></td>\n",
    "            <td><p class=\"normal\">N/A</p></td>\n",
    "        </tr>\n",
    "     </tbody>\n",
    "    </table>\n",
    "<table border=\"1\" cellpadding=\"6\">\t\n",
    "    <tbody>\n",
    "    <tr>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Associated Tasks:</b></p></td>\n",
    "\t\t<td><p class=\"normal\">Classification</p></td>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Missing Values?</b></p></td>\n",
    "\t\t<td><p class=\"normal\">N/A</p></td>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Number of Web Hits:</b></p></td>\n",
    "\t\t<td><p class=\"normal\">N/A</p></td>\n",
    "\t</tr>\n",
    "    </tbody>\n",
    "    </table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WORKFLOW :\n",
    "- Load Data ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1.3'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.19.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data:\n",
    "[Click Here to Download DataSet](https://github.com/ramsha275/ML_Datasets/blob/main/ionosphere_data.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset.\n",
    "df = pd.read_csv('./data/ionosphere_data.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(351, 35)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the shape of the dataset \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's clear from the shape of the data that dataset is not a huge one. Only 351 records are available with 34 features/columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature26</th>\n",
       "      <th>feature27</th>\n",
       "      <th>feature28</th>\n",
       "      <th>feature29</th>\n",
       "      <th>feature30</th>\n",
       "      <th>feature31</th>\n",
       "      <th>feature32</th>\n",
       "      <th>feature33</th>\n",
       "      <th>feature34</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99539</td>\n",
       "      <td>-0.05889</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>0.02306</td>\n",
       "      <td>0.83398</td>\n",
       "      <td>-0.37708</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.03760</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.51171</td>\n",
       "      <td>0.41078</td>\n",
       "      <td>-0.46168</td>\n",
       "      <td>0.21266</td>\n",
       "      <td>-0.34090</td>\n",
       "      <td>0.42267</td>\n",
       "      <td>-0.54487</td>\n",
       "      <td>0.18641</td>\n",
       "      <td>-0.45300</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.18829</td>\n",
       "      <td>0.93035</td>\n",
       "      <td>-0.36156</td>\n",
       "      <td>-0.10868</td>\n",
       "      <td>-0.93597</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.04549</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.26569</td>\n",
       "      <td>-0.20468</td>\n",
       "      <td>-0.18401</td>\n",
       "      <td>-0.19040</td>\n",
       "      <td>-0.11593</td>\n",
       "      <td>-0.16626</td>\n",
       "      <td>-0.06288</td>\n",
       "      <td>-0.13738</td>\n",
       "      <td>-0.02447</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.03365</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00485</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.12062</td>\n",
       "      <td>0.88965</td>\n",
       "      <td>0.01198</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.40220</td>\n",
       "      <td>0.58984</td>\n",
       "      <td>-0.22145</td>\n",
       "      <td>0.43100</td>\n",
       "      <td>-0.17365</td>\n",
       "      <td>0.60436</td>\n",
       "      <td>-0.24180</td>\n",
       "      <td>0.56045</td>\n",
       "      <td>-0.38238</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.45161</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.71216</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.90695</td>\n",
       "      <td>0.51613</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.20099</td>\n",
       "      <td>0.25682</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.32382</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.02401</td>\n",
       "      <td>0.94140</td>\n",
       "      <td>0.06531</td>\n",
       "      <td>0.92106</td>\n",
       "      <td>-0.23255</td>\n",
       "      <td>0.77152</td>\n",
       "      <td>-0.16399</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.65158</td>\n",
       "      <td>0.13290</td>\n",
       "      <td>-0.53206</td>\n",
       "      <td>0.02431</td>\n",
       "      <td>-0.62197</td>\n",
       "      <td>-0.05707</td>\n",
       "      <td>-0.59573</td>\n",
       "      <td>-0.04608</td>\n",
       "      <td>-0.65697</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature1  feature2  feature3  feature4  feature5  feature6  feature7  \\\n",
       "0         1         0   0.99539  -0.05889   0.85243   0.02306   0.83398   \n",
       "1         1         0   1.00000  -0.18829   0.93035  -0.36156  -0.10868   \n",
       "2         1         0   1.00000  -0.03365   1.00000   0.00485   1.00000   \n",
       "3         1         0   1.00000  -0.45161   1.00000   1.00000   0.71216   \n",
       "4         1         0   1.00000  -0.02401   0.94140   0.06531   0.92106   \n",
       "\n",
       "   feature8  feature9  feature10  ...  feature26  feature27  feature28  \\\n",
       "0  -0.37708   1.00000    0.03760  ...   -0.51171    0.41078   -0.46168   \n",
       "1  -0.93597   1.00000   -0.04549  ...   -0.26569   -0.20468   -0.18401   \n",
       "2  -0.12062   0.88965    0.01198  ...   -0.40220    0.58984   -0.22145   \n",
       "3  -1.00000   0.00000    0.00000  ...    0.90695    0.51613    1.00000   \n",
       "4  -0.23255   0.77152   -0.16399  ...   -0.65158    0.13290   -0.53206   \n",
       "\n",
       "   feature29  feature30  feature31  feature32  feature33  feature34  label  \n",
       "0    0.21266   -0.34090    0.42267   -0.54487    0.18641   -0.45300      g  \n",
       "1   -0.19040   -0.11593   -0.16626   -0.06288   -0.13738   -0.02447      b  \n",
       "2    0.43100   -0.17365    0.60436   -0.24180    0.56045   -0.38238      g  \n",
       "3    1.00000   -0.20099    0.25682    1.00000   -0.32382    1.00000      b  \n",
       "4    0.02431   -0.62197   -0.05707   -0.59573   -0.04608   -0.65697      g  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>feature1</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.891738</td>\n",
       "      <td>0.311155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature2</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature3</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.641342</td>\n",
       "      <td>0.497708</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.472135</td>\n",
       "      <td>0.87111</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature4</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.044372</td>\n",
       "      <td>0.441435</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.064735</td>\n",
       "      <td>0.01631</td>\n",
       "      <td>0.194185</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature5</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.601068</td>\n",
       "      <td>0.519862</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.412660</td>\n",
       "      <td>0.80920</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature6</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.115889</td>\n",
       "      <td>0.460810</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.024795</td>\n",
       "      <td>0.02280</td>\n",
       "      <td>0.334655</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature7</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.550095</td>\n",
       "      <td>0.492654</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.211310</td>\n",
       "      <td>0.72873</td>\n",
       "      <td>0.969240</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature8</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.119360</td>\n",
       "      <td>0.520750</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.054840</td>\n",
       "      <td>0.01471</td>\n",
       "      <td>0.445675</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature9</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.511848</td>\n",
       "      <td>0.507066</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.087110</td>\n",
       "      <td>0.68421</td>\n",
       "      <td>0.953240</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature10</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.181345</td>\n",
       "      <td>0.483851</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.048075</td>\n",
       "      <td>0.01829</td>\n",
       "      <td>0.534195</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature11</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.476183</td>\n",
       "      <td>0.563496</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.021120</td>\n",
       "      <td>0.66798</td>\n",
       "      <td>0.957895</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature12</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.155040</td>\n",
       "      <td>0.494817</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.065265</td>\n",
       "      <td>0.02825</td>\n",
       "      <td>0.482375</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature13</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.400801</td>\n",
       "      <td>0.622186</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.64407</td>\n",
       "      <td>0.955505</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature14</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.093414</td>\n",
       "      <td>0.494873</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.073725</td>\n",
       "      <td>0.03027</td>\n",
       "      <td>0.374860</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature15</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.344159</td>\n",
       "      <td>0.652828</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.60194</td>\n",
       "      <td>0.919330</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature16</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.071132</td>\n",
       "      <td>0.458371</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.081705</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.308975</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature17</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.381949</td>\n",
       "      <td>0.618020</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.59091</td>\n",
       "      <td>0.935705</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature18</th>\n",
       "      <td>351.0</td>\n",
       "      <td>-0.003617</td>\n",
       "      <td>0.496762</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.225690</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.195285</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature19</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.359390</td>\n",
       "      <td>0.626267</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.57619</td>\n",
       "      <td>0.899265</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature20</th>\n",
       "      <td>351.0</td>\n",
       "      <td>-0.024025</td>\n",
       "      <td>0.519076</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.234670</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.134370</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature21</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.336695</td>\n",
       "      <td>0.609828</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.49909</td>\n",
       "      <td>0.894865</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature22</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.008296</td>\n",
       "      <td>0.518166</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.243870</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.188760</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature23</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.362475</td>\n",
       "      <td>0.603767</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.53176</td>\n",
       "      <td>0.911235</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature24</th>\n",
       "      <td>351.0</td>\n",
       "      <td>-0.057406</td>\n",
       "      <td>0.527456</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.366885</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.164630</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature25</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.396135</td>\n",
       "      <td>0.578451</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.55389</td>\n",
       "      <td>0.905240</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature26</th>\n",
       "      <td>351.0</td>\n",
       "      <td>-0.071187</td>\n",
       "      <td>0.508495</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.332390</td>\n",
       "      <td>-0.01505</td>\n",
       "      <td>0.156765</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature27</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.541641</td>\n",
       "      <td>0.516205</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.286435</td>\n",
       "      <td>0.70824</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature28</th>\n",
       "      <td>351.0</td>\n",
       "      <td>-0.069538</td>\n",
       "      <td>0.550025</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.443165</td>\n",
       "      <td>-0.01769</td>\n",
       "      <td>0.153535</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature29</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.378445</td>\n",
       "      <td>0.575886</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.49664</td>\n",
       "      <td>0.883465</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature30</th>\n",
       "      <td>351.0</td>\n",
       "      <td>-0.027907</td>\n",
       "      <td>0.507974</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.236885</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.154075</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature31</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.352514</td>\n",
       "      <td>0.571483</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.44277</td>\n",
       "      <td>0.857620</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature32</th>\n",
       "      <td>351.0</td>\n",
       "      <td>-0.003794</td>\n",
       "      <td>0.513574</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.242595</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.200120</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature33</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.349364</td>\n",
       "      <td>0.522663</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.40956</td>\n",
       "      <td>0.813765</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature34</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.014480</td>\n",
       "      <td>0.468337</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.165350</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.171660</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count      mean       std  min       25%      50%       75%  max\n",
       "feature1   351.0  0.891738  0.311155  0.0  1.000000  1.00000  1.000000  1.0\n",
       "feature2   351.0  0.000000  0.000000  0.0  0.000000  0.00000  0.000000  0.0\n",
       "feature3   351.0  0.641342  0.497708 -1.0  0.472135  0.87111  1.000000  1.0\n",
       "feature4   351.0  0.044372  0.441435 -1.0 -0.064735  0.01631  0.194185  1.0\n",
       "feature5   351.0  0.601068  0.519862 -1.0  0.412660  0.80920  1.000000  1.0\n",
       "feature6   351.0  0.115889  0.460810 -1.0 -0.024795  0.02280  0.334655  1.0\n",
       "feature7   351.0  0.550095  0.492654 -1.0  0.211310  0.72873  0.969240  1.0\n",
       "feature8   351.0  0.119360  0.520750 -1.0 -0.054840  0.01471  0.445675  1.0\n",
       "feature9   351.0  0.511848  0.507066 -1.0  0.087110  0.68421  0.953240  1.0\n",
       "feature10  351.0  0.181345  0.483851 -1.0 -0.048075  0.01829  0.534195  1.0\n",
       "feature11  351.0  0.476183  0.563496 -1.0  0.021120  0.66798  0.957895  1.0\n",
       "feature12  351.0  0.155040  0.494817 -1.0 -0.065265  0.02825  0.482375  1.0\n",
       "feature13  351.0  0.400801  0.622186 -1.0  0.000000  0.64407  0.955505  1.0\n",
       "feature14  351.0  0.093414  0.494873 -1.0 -0.073725  0.03027  0.374860  1.0\n",
       "feature15  351.0  0.344159  0.652828 -1.0  0.000000  0.60194  0.919330  1.0\n",
       "feature16  351.0  0.071132  0.458371 -1.0 -0.081705  0.00000  0.308975  1.0\n",
       "feature17  351.0  0.381949  0.618020 -1.0  0.000000  0.59091  0.935705  1.0\n",
       "feature18  351.0 -0.003617  0.496762 -1.0 -0.225690  0.00000  0.195285  1.0\n",
       "feature19  351.0  0.359390  0.626267 -1.0  0.000000  0.57619  0.899265  1.0\n",
       "feature20  351.0 -0.024025  0.519076 -1.0 -0.234670  0.00000  0.134370  1.0\n",
       "feature21  351.0  0.336695  0.609828 -1.0  0.000000  0.49909  0.894865  1.0\n",
       "feature22  351.0  0.008296  0.518166 -1.0 -0.243870  0.00000  0.188760  1.0\n",
       "feature23  351.0  0.362475  0.603767 -1.0  0.000000  0.53176  0.911235  1.0\n",
       "feature24  351.0 -0.057406  0.527456 -1.0 -0.366885  0.00000  0.164630  1.0\n",
       "feature25  351.0  0.396135  0.578451 -1.0  0.000000  0.55389  0.905240  1.0\n",
       "feature26  351.0 -0.071187  0.508495 -1.0 -0.332390 -0.01505  0.156765  1.0\n",
       "feature27  351.0  0.541641  0.516205 -1.0  0.286435  0.70824  0.999945  1.0\n",
       "feature28  351.0 -0.069538  0.550025 -1.0 -0.443165 -0.01769  0.153535  1.0\n",
       "feature29  351.0  0.378445  0.575886 -1.0  0.000000  0.49664  0.883465  1.0\n",
       "feature30  351.0 -0.027907  0.507974 -1.0 -0.236885  0.00000  0.154075  1.0\n",
       "feature31  351.0  0.352514  0.571483 -1.0  0.000000  0.44277  0.857620  1.0\n",
       "feature32  351.0 -0.003794  0.513574 -1.0 -0.242595  0.00000  0.200120  1.0\n",
       "feature33  351.0  0.349364  0.522663 -1.0  0.000000  0.40956  0.813765  1.0\n",
       "feature34  351.0  0.014480  0.468337 -1.0 -0.165350  0.00000  0.171660  1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature1\n",
      "2\n",
      "feature2\n",
      "1\n",
      "feature3\n",
      "219\n",
      "feature4\n",
      "269\n",
      "feature5\n",
      "204\n",
      "feature6\n",
      "259\n",
      "feature7\n",
      "231\n",
      "feature8\n",
      "260\n",
      "feature9\n",
      "244\n",
      "feature10\n",
      "267\n",
      "feature11\n",
      "246\n",
      "feature12\n",
      "269\n",
      "feature13\n",
      "238\n",
      "feature14\n",
      "266\n",
      "feature15\n",
      "234\n",
      "feature16\n",
      "270\n",
      "feature17\n",
      "254\n",
      "feature18\n",
      "280\n",
      "feature19\n",
      "254\n",
      "feature20\n",
      "266\n",
      "feature21\n",
      "248\n",
      "feature22\n",
      "265\n",
      "feature23\n",
      "248\n",
      "feature24\n",
      "264\n",
      "feature25\n",
      "256\n",
      "feature26\n",
      "273\n",
      "feature27\n",
      "256\n",
      "feature28\n",
      "281\n",
      "feature29\n",
      "244\n",
      "feature30\n",
      "266\n",
      "feature31\n",
      "243\n",
      "feature32\n",
      "263\n",
      "feature33\n",
      "245\n",
      "feature34\n",
      "263\n",
      "label\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for feature in df:\n",
    "    print(feature)\n",
    "    print(len(df[feature].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['feature2'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df.columns[1], inplace=True, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>feature11</th>\n",
       "      <th>...</th>\n",
       "      <th>feature26</th>\n",
       "      <th>feature27</th>\n",
       "      <th>feature28</th>\n",
       "      <th>feature29</th>\n",
       "      <th>feature30</th>\n",
       "      <th>feature31</th>\n",
       "      <th>feature32</th>\n",
       "      <th>feature33</th>\n",
       "      <th>feature34</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.99539</td>\n",
       "      <td>-0.05889</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>0.02306</td>\n",
       "      <td>0.83398</td>\n",
       "      <td>-0.37708</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.03760</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.51171</td>\n",
       "      <td>0.41078</td>\n",
       "      <td>-0.46168</td>\n",
       "      <td>0.21266</td>\n",
       "      <td>-0.34090</td>\n",
       "      <td>0.42267</td>\n",
       "      <td>-0.54487</td>\n",
       "      <td>0.18641</td>\n",
       "      <td>-0.45300</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.18829</td>\n",
       "      <td>0.93035</td>\n",
       "      <td>-0.36156</td>\n",
       "      <td>-0.10868</td>\n",
       "      <td>-0.93597</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.04549</td>\n",
       "      <td>0.50874</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.26569</td>\n",
       "      <td>-0.20468</td>\n",
       "      <td>-0.18401</td>\n",
       "      <td>-0.19040</td>\n",
       "      <td>-0.11593</td>\n",
       "      <td>-0.16626</td>\n",
       "      <td>-0.06288</td>\n",
       "      <td>-0.13738</td>\n",
       "      <td>-0.02447</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.03365</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00485</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.12062</td>\n",
       "      <td>0.88965</td>\n",
       "      <td>0.01198</td>\n",
       "      <td>0.73082</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.40220</td>\n",
       "      <td>0.58984</td>\n",
       "      <td>-0.22145</td>\n",
       "      <td>0.43100</td>\n",
       "      <td>-0.17365</td>\n",
       "      <td>0.60436</td>\n",
       "      <td>-0.24180</td>\n",
       "      <td>0.56045</td>\n",
       "      <td>-0.38238</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.45161</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.71216</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.90695</td>\n",
       "      <td>0.51613</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.20099</td>\n",
       "      <td>0.25682</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.32382</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.02401</td>\n",
       "      <td>0.94140</td>\n",
       "      <td>0.06531</td>\n",
       "      <td>0.92106</td>\n",
       "      <td>-0.23255</td>\n",
       "      <td>0.77152</td>\n",
       "      <td>-0.16399</td>\n",
       "      <td>0.52798</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.65158</td>\n",
       "      <td>0.13290</td>\n",
       "      <td>-0.53206</td>\n",
       "      <td>0.02431</td>\n",
       "      <td>-0.62197</td>\n",
       "      <td>-0.05707</td>\n",
       "      <td>-0.59573</td>\n",
       "      <td>-0.04608</td>\n",
       "      <td>-0.65697</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature1  feature3  feature4  feature5  feature6  feature7  feature8  \\\n",
       "0         1   0.99539  -0.05889   0.85243   0.02306   0.83398  -0.37708   \n",
       "1         1   1.00000  -0.18829   0.93035  -0.36156  -0.10868  -0.93597   \n",
       "2         1   1.00000  -0.03365   1.00000   0.00485   1.00000  -0.12062   \n",
       "3         1   1.00000  -0.45161   1.00000   1.00000   0.71216  -1.00000   \n",
       "4         1   1.00000  -0.02401   0.94140   0.06531   0.92106  -0.23255   \n",
       "\n",
       "   feature9  feature10  feature11  ...  feature26  feature27  feature28  \\\n",
       "0   1.00000    0.03760    0.85243  ...   -0.51171    0.41078   -0.46168   \n",
       "1   1.00000   -0.04549    0.50874  ...   -0.26569   -0.20468   -0.18401   \n",
       "2   0.88965    0.01198    0.73082  ...   -0.40220    0.58984   -0.22145   \n",
       "3   0.00000    0.00000    0.00000  ...    0.90695    0.51613    1.00000   \n",
       "4   0.77152   -0.16399    0.52798  ...   -0.65158    0.13290   -0.53206   \n",
       "\n",
       "   feature29  feature30  feature31  feature32  feature33  feature34  label  \n",
       "0    0.21266   -0.34090    0.42267   -0.54487    0.18641   -0.45300      g  \n",
       "1   -0.19040   -0.11593   -0.16626   -0.06288   -0.13738   -0.02447      b  \n",
       "2    0.43100   -0.17365    0.60436   -0.24180    0.56045   -0.38238      g  \n",
       "3    1.00000   -0.20099    0.25682    1.00000   -0.32382    1.00000      b  \n",
       "4    0.02431   -0.62197   -0.05707   -0.59573   -0.04608   -0.65697      g  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 351 entries, 0 to 350\n",
      "Data columns (total 34 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   feature1   351 non-null    int64  \n",
      " 1   feature3   351 non-null    float64\n",
      " 2   feature4   351 non-null    float64\n",
      " 3   feature5   351 non-null    float64\n",
      " 4   feature6   351 non-null    float64\n",
      " 5   feature7   351 non-null    float64\n",
      " 6   feature8   351 non-null    float64\n",
      " 7   feature9   351 non-null    float64\n",
      " 8   feature10  351 non-null    float64\n",
      " 9   feature11  351 non-null    float64\n",
      " 10  feature12  351 non-null    float64\n",
      " 11  feature13  351 non-null    float64\n",
      " 12  feature14  351 non-null    float64\n",
      " 13  feature15  351 non-null    float64\n",
      " 14  feature16  351 non-null    float64\n",
      " 15  feature17  351 non-null    float64\n",
      " 16  feature18  351 non-null    float64\n",
      " 17  feature19  351 non-null    float64\n",
      " 18  feature20  351 non-null    float64\n",
      " 19  feature21  351 non-null    float64\n",
      " 20  feature22  351 non-null    float64\n",
      " 21  feature23  351 non-null    float64\n",
      " 22  feature24  351 non-null    float64\n",
      " 23  feature25  351 non-null    float64\n",
      " 24  feature26  351 non-null    float64\n",
      " 25  feature27  351 non-null    float64\n",
      " 26  feature28  351 non-null    float64\n",
      " 27  feature29  351 non-null    float64\n",
      " 28  feature30  351 non-null    float64\n",
      " 29  feature31  351 non-null    float64\n",
      " 30  feature32  351 non-null    float64\n",
      " 31  feature33  351 non-null    float64\n",
      " 32  feature34  351 non-null    float64\n",
      " 33  label      351 non-null    object \n",
      "dtypes: float64(32), int64(1), object(1)\n",
      "memory usage: 93.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for feature in df:\\n    print(feature)\\n    df[feature].hist()\\n    plt.show()'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''for feature in df:\n",
    "    print(feature)\n",
    "    df[feature].hist()\n",
    "    plt.show()'''\n",
    "\n",
    "# df.hist()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>feature11</th>\n",
       "      <th>...</th>\n",
       "      <th>feature25</th>\n",
       "      <th>feature26</th>\n",
       "      <th>feature27</th>\n",
       "      <th>feature28</th>\n",
       "      <th>feature29</th>\n",
       "      <th>feature30</th>\n",
       "      <th>feature31</th>\n",
       "      <th>feature32</th>\n",
       "      <th>feature33</th>\n",
       "      <th>feature34</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.891738</td>\n",
       "      <td>0.641342</td>\n",
       "      <td>0.044372</td>\n",
       "      <td>0.601068</td>\n",
       "      <td>0.115889</td>\n",
       "      <td>0.550095</td>\n",
       "      <td>0.119360</td>\n",
       "      <td>0.511848</td>\n",
       "      <td>0.181345</td>\n",
       "      <td>0.476183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.396135</td>\n",
       "      <td>-0.071187</td>\n",
       "      <td>0.541641</td>\n",
       "      <td>-0.069538</td>\n",
       "      <td>0.378445</td>\n",
       "      <td>-0.027907</td>\n",
       "      <td>0.352514</td>\n",
       "      <td>-0.003794</td>\n",
       "      <td>0.349364</td>\n",
       "      <td>0.014480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.311155</td>\n",
       "      <td>0.497708</td>\n",
       "      <td>0.441435</td>\n",
       "      <td>0.519862</td>\n",
       "      <td>0.460810</td>\n",
       "      <td>0.492654</td>\n",
       "      <td>0.520750</td>\n",
       "      <td>0.507066</td>\n",
       "      <td>0.483851</td>\n",
       "      <td>0.563496</td>\n",
       "      <td>...</td>\n",
       "      <td>0.578451</td>\n",
       "      <td>0.508495</td>\n",
       "      <td>0.516205</td>\n",
       "      <td>0.550025</td>\n",
       "      <td>0.575886</td>\n",
       "      <td>0.507974</td>\n",
       "      <td>0.571483</td>\n",
       "      <td>0.513574</td>\n",
       "      <td>0.522663</td>\n",
       "      <td>0.468337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.472135</td>\n",
       "      <td>-0.064735</td>\n",
       "      <td>0.412660</td>\n",
       "      <td>-0.024795</td>\n",
       "      <td>0.211310</td>\n",
       "      <td>-0.054840</td>\n",
       "      <td>0.087110</td>\n",
       "      <td>-0.048075</td>\n",
       "      <td>0.021120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.332390</td>\n",
       "      <td>0.286435</td>\n",
       "      <td>-0.443165</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.236885</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.242595</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.165350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871110</td>\n",
       "      <td>0.016310</td>\n",
       "      <td>0.809200</td>\n",
       "      <td>0.022800</td>\n",
       "      <td>0.728730</td>\n",
       "      <td>0.014710</td>\n",
       "      <td>0.684210</td>\n",
       "      <td>0.018290</td>\n",
       "      <td>0.667980</td>\n",
       "      <td>...</td>\n",
       "      <td>0.553890</td>\n",
       "      <td>-0.015050</td>\n",
       "      <td>0.708240</td>\n",
       "      <td>-0.017690</td>\n",
       "      <td>0.496640</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.442770</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.409560</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.194185</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.334655</td>\n",
       "      <td>0.969240</td>\n",
       "      <td>0.445675</td>\n",
       "      <td>0.953240</td>\n",
       "      <td>0.534195</td>\n",
       "      <td>0.957895</td>\n",
       "      <td>...</td>\n",
       "      <td>0.905240</td>\n",
       "      <td>0.156765</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>0.153535</td>\n",
       "      <td>0.883465</td>\n",
       "      <td>0.154075</td>\n",
       "      <td>0.857620</td>\n",
       "      <td>0.200120</td>\n",
       "      <td>0.813765</td>\n",
       "      <td>0.171660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature1    feature3    feature4    feature5    feature6    feature7  \\\n",
       "count  351.000000  351.000000  351.000000  351.000000  351.000000  351.000000   \n",
       "mean     0.891738    0.641342    0.044372    0.601068    0.115889    0.550095   \n",
       "std      0.311155    0.497708    0.441435    0.519862    0.460810    0.492654   \n",
       "min      0.000000   -1.000000   -1.000000   -1.000000   -1.000000   -1.000000   \n",
       "25%      1.000000    0.472135   -0.064735    0.412660   -0.024795    0.211310   \n",
       "50%      1.000000    0.871110    0.016310    0.809200    0.022800    0.728730   \n",
       "75%      1.000000    1.000000    0.194185    1.000000    0.334655    0.969240   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "         feature8    feature9   feature10   feature11  ...   feature25  \\\n",
       "count  351.000000  351.000000  351.000000  351.000000  ...  351.000000   \n",
       "mean     0.119360    0.511848    0.181345    0.476183  ...    0.396135   \n",
       "std      0.520750    0.507066    0.483851    0.563496  ...    0.578451   \n",
       "min     -1.000000   -1.000000   -1.000000   -1.000000  ...   -1.000000   \n",
       "25%     -0.054840    0.087110   -0.048075    0.021120  ...    0.000000   \n",
       "50%      0.014710    0.684210    0.018290    0.667980  ...    0.553890   \n",
       "75%      0.445675    0.953240    0.534195    0.957895  ...    0.905240   \n",
       "max      1.000000    1.000000    1.000000    1.000000  ...    1.000000   \n",
       "\n",
       "        feature26   feature27   feature28   feature29   feature30   feature31  \\\n",
       "count  351.000000  351.000000  351.000000  351.000000  351.000000  351.000000   \n",
       "mean    -0.071187    0.541641   -0.069538    0.378445   -0.027907    0.352514   \n",
       "std      0.508495    0.516205    0.550025    0.575886    0.507974    0.571483   \n",
       "min     -1.000000   -1.000000   -1.000000   -1.000000   -1.000000   -1.000000   \n",
       "25%     -0.332390    0.286435   -0.443165    0.000000   -0.236885    0.000000   \n",
       "50%     -0.015050    0.708240   -0.017690    0.496640    0.000000    0.442770   \n",
       "75%      0.156765    0.999945    0.153535    0.883465    0.154075    0.857620   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "        feature32   feature33   feature34  \n",
       "count  351.000000  351.000000  351.000000  \n",
       "mean    -0.003794    0.349364    0.014480  \n",
       "std      0.513574    0.522663    0.468337  \n",
       "min     -1.000000   -1.000000   -1.000000  \n",
       "25%     -0.242595    0.000000   -0.165350  \n",
       "50%      0.000000    0.409560    0.000000  \n",
       "75%      0.200120    0.813765    0.171660  \n",
       "max      1.000000    1.000000    1.000000  \n",
       "\n",
       "[8 rows x 33 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check summary statistics\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check Missing Values ( If Exist ; Fill each record with mean of its feature ) or any usless column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature1     0\n",
       "feature3     0\n",
       "feature4     0\n",
       "feature5     0\n",
       "feature6     0\n",
       "feature7     0\n",
       "feature8     0\n",
       "feature9     0\n",
       "feature10    0\n",
       "feature11    0\n",
       "feature12    0\n",
       "feature13    0\n",
       "feature14    0\n",
       "feature15    0\n",
       "feature16    0\n",
       "feature17    0\n",
       "feature18    0\n",
       "feature19    0\n",
       "feature20    0\n",
       "feature21    0\n",
       "feature22    0\n",
       "feature23    0\n",
       "feature24    0\n",
       "feature25    0\n",
       "feature26    0\n",
       "feature27    0\n",
       "feature28    0\n",
       "feature29    0\n",
       "feature30    0\n",
       "feature31    0\n",
       "feature32    0\n",
       "feature33    0\n",
       "feature34    0\n",
       "label        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = [1 if lbl == 'g' else 0 for lbl in df['label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = df.sample(frac= 0.6, random_state=125)\n",
    "test_data = df.drop(train_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = train_data.iloc[:,-1]\n",
    "train_data = train_data.iloc[:,0:-1]\n",
    "test_label = test_data.iloc[:,-1]\n",
    "test_data = test_data.iloc[:,0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(columns= 'label', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>feature11</th>\n",
       "      <th>...</th>\n",
       "      <th>feature25</th>\n",
       "      <th>feature26</th>\n",
       "      <th>feature27</th>\n",
       "      <th>feature28</th>\n",
       "      <th>feature29</th>\n",
       "      <th>feature30</th>\n",
       "      <th>feature31</th>\n",
       "      <th>feature32</th>\n",
       "      <th>feature33</th>\n",
       "      <th>feature34</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.08013</td>\n",
       "      <td>0.96775</td>\n",
       "      <td>-0.00482</td>\n",
       "      <td>0.96683</td>\n",
       "      <td>-0.00722</td>\n",
       "      <td>0.87980</td>\n",
       "      <td>-0.03923</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.98164</td>\n",
       "      <td>0.02003</td>\n",
       "      <td>0.93772</td>\n",
       "      <td>-0.03034</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.05843</td>\n",
       "      <td>0.92774</td>\n",
       "      <td>-0.03464</td>\n",
       "      <td>0.92226</td>\n",
       "      <td>-0.03673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.14754</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.04918</td>\n",
       "      <td>0.57377</td>\n",
       "      <td>-0.01639</td>\n",
       "      <td>0.65574</td>\n",
       "      <td>0.01639</td>\n",
       "      <td>0.85246</td>\n",
       "      <td>...</td>\n",
       "      <td>0.31148</td>\n",
       "      <td>-0.34426</td>\n",
       "      <td>0.52385</td>\n",
       "      <td>-0.20325</td>\n",
       "      <td>0.32787</td>\n",
       "      <td>-0.03279</td>\n",
       "      <td>0.27869</td>\n",
       "      <td>-0.44262</td>\n",
       "      <td>0.49180</td>\n",
       "      <td>-0.06557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>1</td>\n",
       "      <td>0.89706</td>\n",
       "      <td>0.38235</td>\n",
       "      <td>0.91176</td>\n",
       "      <td>0.37500</td>\n",
       "      <td>0.74265</td>\n",
       "      <td>0.67647</td>\n",
       "      <td>0.45588</td>\n",
       "      <td>0.77941</td>\n",
       "      <td>0.19118</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.74265</td>\n",
       "      <td>-0.12500</td>\n",
       "      <td>-0.67925</td>\n",
       "      <td>-0.24131</td>\n",
       "      <td>-0.55147</td>\n",
       "      <td>-0.42647</td>\n",
       "      <td>-0.44118</td>\n",
       "      <td>-0.50735</td>\n",
       "      <td>-0.28676</td>\n",
       "      <td>-0.56618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>1</td>\n",
       "      <td>0.84557</td>\n",
       "      <td>-0.08580</td>\n",
       "      <td>-0.31745</td>\n",
       "      <td>-0.80553</td>\n",
       "      <td>-0.08961</td>\n",
       "      <td>-0.56435</td>\n",
       "      <td>0.80648</td>\n",
       "      <td>0.04576</td>\n",
       "      <td>0.89514</td>\n",
       "      <td>...</td>\n",
       "      <td>0.78932</td>\n",
       "      <td>-0.03718</td>\n",
       "      <td>0.70882</td>\n",
       "      <td>-0.25288</td>\n",
       "      <td>0.77884</td>\n",
       "      <td>-0.14109</td>\n",
       "      <td>-0.21354</td>\n",
       "      <td>-0.78170</td>\n",
       "      <td>-0.18494</td>\n",
       "      <td>-0.59867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.77941</td>\n",
       "      <td>-0.99265</td>\n",
       "      <td>0.80882</td>\n",
       "      <td>0.55147</td>\n",
       "      <td>-0.41912</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature1  feature3  feature4  feature5  feature6  feature7  feature8  \\\n",
       "270         1   1.00000   0.08013   0.96775  -0.00482   0.96683  -0.00722   \n",
       "116         1   1.00000  -0.14754   1.00000   0.04918   0.57377  -0.01639   \n",
       "135         1   0.89706   0.38235   0.91176   0.37500   0.74265   0.67647   \n",
       "91          1   0.84557  -0.08580  -0.31745  -0.80553  -0.08961  -0.56435   \n",
       "100         1   1.00000  -1.00000   0.00000   0.00000   0.77941  -0.99265   \n",
       "\n",
       "     feature9  feature10  feature11  ...  feature25  feature26  feature27  \\\n",
       "270   0.87980   -0.03923    1.00000  ...    0.98164    0.02003    0.93772   \n",
       "116   0.65574    0.01639    0.85246  ...    0.31148   -0.34426    0.52385   \n",
       "135   0.45588    0.77941    0.19118  ...   -0.74265   -0.12500   -0.67925   \n",
       "91    0.80648    0.04576    0.89514  ...    0.78932   -0.03718    0.70882   \n",
       "100   0.80882    0.55147   -0.41912  ...   -1.00000   -1.00000   -1.00000   \n",
       "\n",
       "     feature28  feature29  feature30  feature31  feature32  feature33  \\\n",
       "270   -0.03034    1.00000   -0.05843    0.92774   -0.03464    0.92226   \n",
       "116   -0.20325    0.32787   -0.03279    0.27869   -0.44262    0.49180   \n",
       "135   -0.24131   -0.55147   -0.42647   -0.44118   -0.50735   -0.28676   \n",
       "91    -0.25288    0.77884   -0.14109   -0.21354   -0.78170   -0.18494   \n",
       "100   -1.00000    1.00000   -1.00000    1.00000   -1.00000    0.00000   \n",
       "\n",
       "     feature34  \n",
       "270   -0.03673  \n",
       "116   -0.06557  \n",
       "135   -0.56618  \n",
       "91    -0.59867  \n",
       "100    0.00000  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "270    1\n",
       "116    0\n",
       "135    1\n",
       "91     0\n",
       "100    0\n",
       "      ..\n",
       "213    1\n",
       "161    1\n",
       "141    1\n",
       "59     0\n",
       "113    1\n",
       "Name: label, Length: 211, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Standardized the Input Variables. **Hint**: Centeralized the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Normalize the data\n",
    "# train_mean = train_data.mean()\n",
    "# train_data -= train_mean\n",
    "# train_std = train_data.std()\n",
    "# train_data /= train_std\n",
    "# test_data -= train_mean\n",
    "# test_data /= train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Encode labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Shuffle the data if needed.\n",
    "- Split into 60 and 40 ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now sample the dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(211, 33)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140, 33)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(211,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "211"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_label.sum()/len(train_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = train_label.to_numpy().astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label = test_label.to_numpy().astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_set = np.array(train_set.as_matrix())\n",
    "#train_label = np.array(pd.DataFrame(train_label).as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_data))\n",
    "print(type(train_label))\n",
    "print(type(test_data))\n",
    "print(type(test_label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "float32\n",
      "float32\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "print(train_data.dtype)\n",
    "print(train_label.dtype)\n",
    "print(test_label.dtype)\n",
    "print(test_data.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Model : 1 hidden layers including 16 unit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "# Define model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(train_data.shape[1],)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1,  activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                2176      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 6,401\n",
      "Trainable params: 6,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Compilation Step (Note : Its a Binary problem , select loss , metrics according to it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "\n",
    "model.compile(optimizer = 'RMSprop', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Train the Model with Epochs (100)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "11/11 [==============================] - 3s 144ms/step - loss: 0.6436 - accuracy: 0.6655 - val_loss: 0.5043 - val_accuracy: 0.8140\n",
      "Epoch 2/75\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.5410 - accuracy: 0.7587 - val_loss: 0.4471 - val_accuracy: 0.8605\n",
      "Epoch 3/75\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.4993 - accuracy: 0.7991 - val_loss: 0.4072 - val_accuracy: 0.9070\n",
      "Epoch 4/75\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.4606 - accuracy: 0.8102 - val_loss: 0.3668 - val_accuracy: 0.9070\n",
      "Epoch 5/75\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.3879 - accuracy: 0.9009 - val_loss: 0.3307 - val_accuracy: 0.9070\n",
      "Epoch 6/75\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3576 - accuracy: 0.8880 - val_loss: 0.2999 - val_accuracy: 0.9302\n",
      "Epoch 7/75\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 0.3526 - accuracy: 0.8959 - val_loss: 0.2723 - val_accuracy: 0.9302\n",
      "Epoch 8/75\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.2702 - accuracy: 0.9273 - val_loss: 0.2438 - val_accuracy: 0.9302\n",
      "Epoch 9/75\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.2602 - accuracy: 0.9074 - val_loss: 0.2193 - val_accuracy: 0.9535\n",
      "Epoch 10/75\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.2435 - accuracy: 0.9370 - val_loss: 0.2052 - val_accuracy: 0.9535\n",
      "Epoch 11/75\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.2292 - accuracy: 0.9244 - val_loss: 0.2001 - val_accuracy: 0.9535\n",
      "Epoch 12/75\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.2325 - accuracy: 0.9281 - val_loss: 0.1795 - val_accuracy: 0.9767\n",
      "Epoch 13/75\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.1850 - accuracy: 0.9398 - val_loss: 0.1736 - val_accuracy: 0.9767\n",
      "Epoch 14/75\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.1634 - accuracy: 0.9492 - val_loss: 0.1601 - val_accuracy: 0.9767\n",
      "Epoch 15/75\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.2205 - accuracy: 0.9335 - val_loss: 0.1623 - val_accuracy: 0.9767\n",
      "Epoch 16/75\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.1402 - accuracy: 0.9558 - val_loss: 0.1519 - val_accuracy: 0.9767\n",
      "Epoch 17/75\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.1467 - accuracy: 0.9392 - val_loss: 0.1499 - val_accuracy: 0.9767\n",
      "Epoch 18/75\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.1533 - accuracy: 0.9284 - val_loss: 0.1359 - val_accuracy: 0.9767\n",
      "Epoch 19/75\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.1649 - accuracy: 0.9395 - val_loss: 0.1313 - val_accuracy: 0.9767\n",
      "Epoch 20/75\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.1363 - accuracy: 0.9749 - val_loss: 0.1386 - val_accuracy: 0.9767\n",
      "Epoch 21/75\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.1323 - accuracy: 0.9406 - val_loss: 0.1454 - val_accuracy: 0.9767\n",
      "Epoch 22/75\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.1652 - accuracy: 0.9430 - val_loss: 0.1284 - val_accuracy: 0.9767\n",
      "Epoch 23/75\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.1152 - accuracy: 0.9634 - val_loss: 0.1576 - val_accuracy: 0.9767\n",
      "Epoch 24/75\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.1563 - accuracy: 0.9527 - val_loss: 0.1324 - val_accuracy: 0.9767\n",
      "Epoch 25/75\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0602 - accuracy: 0.9923 - val_loss: 0.1213 - val_accuracy: 0.9767\n",
      "Epoch 26/75\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0959 - accuracy: 0.9770 - val_loss: 0.1257 - val_accuracy: 0.9767\n",
      "Epoch 27/75\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.1239 - accuracy: 0.9537 - val_loss: 0.1380 - val_accuracy: 0.9767\n",
      "Epoch 28/75\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.1041 - accuracy: 0.9512 - val_loss: 0.1264 - val_accuracy: 0.9767\n",
      "Epoch 29/75\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0811 - accuracy: 0.9706 - val_loss: 0.1405 - val_accuracy: 0.9767\n",
      "Epoch 30/75\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0565 - accuracy: 0.9869 - val_loss: 0.1360 - val_accuracy: 0.9767\n",
      "Epoch 31/75\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0913 - accuracy: 0.9700 - val_loss: 0.1353 - val_accuracy: 0.9767\n",
      "Epoch 32/75\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0797 - accuracy: 0.9503 - val_loss: 0.1537 - val_accuracy: 0.9767\n",
      "Epoch 33/75\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0464 - accuracy: 0.9938 - val_loss: 0.1483 - val_accuracy: 0.9767\n",
      "Epoch 34/75\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0419 - accuracy: 0.9880 - val_loss: 0.1244 - val_accuracy: 0.9767\n",
      "Epoch 35/75\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0651 - accuracy: 0.9770 - val_loss: 0.1438 - val_accuracy: 0.9767\n",
      "Epoch 36/75\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0708 - accuracy: 0.9802 - val_loss: 0.1371 - val_accuracy: 0.9767\n",
      "Epoch 37/75\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.0493 - accuracy: 0.9919 - val_loss: 0.1491 - val_accuracy: 0.9767\n",
      "Epoch 38/75\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0729 - accuracy: 0.9716 - val_loss: 0.1362 - val_accuracy: 0.9767\n",
      "Epoch 39/75\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0383 - accuracy: 0.9931 - val_loss: 0.1438 - val_accuracy: 0.9767\n",
      "Epoch 40/75\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0273 - accuracy: 0.9990 - val_loss: 0.1367 - val_accuracy: 0.9767\n",
      "Epoch 41/75\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0533 - accuracy: 0.9915 - val_loss: 0.1294 - val_accuracy: 0.9767\n",
      "Epoch 42/75\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0615 - accuracy: 0.9836 - val_loss: 0.1282 - val_accuracy: 0.9767\n",
      "Epoch 43/75\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0289 - accuracy: 0.9925 - val_loss: 0.1394 - val_accuracy: 0.9767\n",
      "Epoch 44/75\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0351 - accuracy: 0.9879 - val_loss: 0.1469 - val_accuracy: 0.9767\n",
      "Epoch 45/75\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0297 - accuracy: 0.9890 - val_loss: 0.1359 - val_accuracy: 0.9767\n",
      "Epoch 46/75\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0491 - accuracy: 0.9880 - val_loss: 0.1232 - val_accuracy: 0.9767\n",
      "Epoch 47/75\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0370 - accuracy: 0.9922 - val_loss: 0.1311 - val_accuracy: 0.9767\n",
      "Epoch 48/75\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0316 - accuracy: 0.9973 - val_loss: 0.1153 - val_accuracy: 0.9767\n",
      "Epoch 49/75\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0194 - accuracy: 0.9956 - val_loss: 0.1124 - val_accuracy: 0.9767\n",
      "Epoch 50/75\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0254 - accuracy: 0.9956 - val_loss: 0.1089 - val_accuracy: 0.9767\n",
      "Epoch 51/75\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0319 - accuracy: 0.9956 - val_loss: 0.1250 - val_accuracy: 0.9767\n",
      "Epoch 52/75\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0290 - accuracy: 0.9890 - val_loss: 0.1204 - val_accuracy: 0.9767\n",
      "Epoch 53/75\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0313 - accuracy: 0.9946 - val_loss: 0.1317 - val_accuracy: 0.9767\n",
      "Epoch 54/75\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0264 - accuracy: 0.9965 - val_loss: 0.1252 - val_accuracy: 0.9767\n",
      "Epoch 55/75\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0275 - accuracy: 0.9946 - val_loss: 0.1149 - val_accuracy: 0.9767\n",
      "Epoch 56/75\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0375 - accuracy: 0.9838 - val_loss: 0.1202 - val_accuracy: 0.9767\n",
      "Epoch 57/75\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0306 - accuracy: 0.9916 - val_loss: 0.1214 - val_accuracy: 0.9767\n",
      "Epoch 58/75\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0367 - accuracy: 0.9919 - val_loss: 0.0977 - val_accuracy: 0.9767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/75\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.1166 - val_accuracy: 0.9767\n",
      "Epoch 60/75\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.1218 - val_accuracy: 0.9767\n",
      "Epoch 61/75\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0223 - accuracy: 1.0000 - val_loss: 0.1451 - val_accuracy: 0.9535\n",
      "Epoch 62/75\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0094 - accuracy: 0.9990 - val_loss: 0.0982 - val_accuracy: 0.9535\n",
      "Epoch 63/75\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.1390 - val_accuracy: 0.9535\n",
      "Epoch 64/75\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0168 - accuracy: 0.9963 - val_loss: 0.1073 - val_accuracy: 0.9535\n",
      "Epoch 65/75\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0231 - accuracy: 0.9979 - val_loss: 0.1093 - val_accuracy: 0.9535\n",
      "Epoch 66/75\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0158 - accuracy: 0.9965 - val_loss: 0.1230 - val_accuracy: 0.9535\n",
      "Epoch 67/75\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.1218 - val_accuracy: 0.9535\n",
      "Epoch 68/75\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.1291 - val_accuracy: 0.9535\n",
      "Epoch 69/75\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.1590 - val_accuracy: 0.9535\n",
      "Epoch 70/75\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0268 - accuracy: 0.9838 - val_loss: 0.1387 - val_accuracy: 0.9535\n",
      "Epoch 71/75\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0303 - accuracy: 0.9838 - val_loss: 0.1238 - val_accuracy: 0.9535\n",
      "Epoch 72/75\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.1203 - val_accuracy: 0.9535\n",
      "Epoch 73/75\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0488 - accuracy: 0.9823 - val_loss: 0.0777 - val_accuracy: 0.9767\n",
      "Epoch 74/75\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0149 - accuracy: 0.9933 - val_loss: 0.1111 - val_accuracy: 0.9535\n",
      "Epoch 75/75\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0354 - accuracy: 0.9838 - val_loss: 0.0845 - val_accuracy: 0.9767\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data, train_label, validation_split=0.2, epochs=75, batch_size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "\n",
    "epochs = range(75)\n",
    "plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc_values = history_dict['accuracy']\n",
    "val_acc_values = history_dict['val_accuracy']\n",
    "plt.plot(epochs, acc_values, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc_values, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Evaluation Step\n",
    "- Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2678 - accuracy: 0.9500\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test_data, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2677903175354004, 0.949999988079071]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If the model gets overfit tune your model by changing the units , No. of layers , epochs , add dropout layer or add Regularizer according to the need .\n",
    "- Prediction should be > **92%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (predictions > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[49,  6],\n",
       "       [ 1, 84]], dtype=int32)>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.confusion_matrix(\n",
    "    test_label, y_pred, num_classes=2, weights=None, dtype=tf.dtypes.int32,\n",
    "    name=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    " # It will evaluate the logical expression y_predict>0.25 and return True or False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
